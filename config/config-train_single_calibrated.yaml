#Table where the frequencies and frequencies IDs are stored
freq_table_src: "../data/frequencies.csv"

#Table where each measurement point is stored
meas_table_src: "../datasets/EIS-vs-SOC-jun2022/impedance.csv"

#Models Folder
models_path: '../data/models'

#root generate image files path
root_images_path: '../data/images'

#root generate image files path for test
root_test_images_path: '../data/test_images'

results_path: '../results'

#Model score metrics
model_metrics: 'accuracy'

#Relevant fields in the measurement table
battery_id_field: "BATTERY_ID"
measure_id_field: "MEASURE_ID"
frequency_id_field: "FREQUENCY_ID"
soc_field: "SOC"
impedance_field: "IMPEDANCE_VALUE"

#Store the results of the classification experiments here
classification_results_out: '../results/classification-results.txt'

#Store the pca scatter plots here
pca_scatter_plots_out: '../results/scatter-plots.svg'

# Root working folder (local,Google Drive, Amazon SageMaker Studio, Azure ML Workspace, ...)
working_folder: '/home/studio-lab-user/'

# SOC List
soc_list: ['100','090','080','070','060','050','040','030','020','010']

# Data acquition file to load from dateset folder
# Measures "05_8" 06_*  keep out for test
all_batteries: ['05_3','05_4','05_5','05_6','05_7']

test_measure_list: ['06_04','06_05','06_06','06_07','06_08']

# Experiment name prefix
# This prefix will be used to generate name of files and folders to store the model and the results of the experiment
# Note1: if you want to run multiple experiments you need to change the name prefix
# Note2: if you want to run in a Colab virtual machine generated images and model will be stored in your Google Drive
experiment_name_prefix: "Paper_MES_X20_calibration_BATT05_"

# Enable/disable image dataset generation
# Image genaration is time and resource comsuming task. 
# You need to generate image just once for every cross validation experiment
# generate_images = False
generate_images: True


# The number of epochs is a hyperparameter that defines the number times that the 
# learning algorithm will work through the entire training dataset
# n_epochs=30
n_epochs: 50